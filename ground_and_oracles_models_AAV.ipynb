{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from utils.dataloader import *\n",
    "from utils.GFP import *\n",
    "from utils.AAV import * \n",
    "from utils.pesudo_MSA import AAV_END, AAV_START, WT_AAV2\n",
    "from utils.torch_utils import *\n",
    "from Groundtruth_model.CNN import *\n",
    "from Groundtruth_model.ensemble import *\n",
    "from Oracle_model.oracle_from_CbAS import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groundtruth model using a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch = 400; lr=0.0005; batch_size=128; seed=2; model_id = 0\n",
    "device = torch.device(\"cuda\")\n",
    "#################################################\n",
    "# seed_everything(seed=seed)\n",
    "# df = pd.read_csv('GFP_data/gfp_data.csv')\n",
    "# X, y = get_gfp_X_y_aa(df, large_only=True, ignore_stops=True)\n",
    "df = pd.read_csv('AAV_data/AAV_library.csv')\n",
    "X, y, seqs = get_AAV_X_y_aa(df, large_only=False, return_str=True)\n",
    "#################################################\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=seed, shuffle=True)\n",
    "train_set = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# train_set = torch.utils.data.TensorDataset(X, y)\n",
    "# X_test, y_test = X, y\n",
    "loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "CNN = CNN_ground_AAV(seq_len = X.shape[1], hidden_fc=512, hidden_conv=12, n_chars = 21)\n",
    "CNN = CNN.to(device=device)\n",
    "criterion = NLL_loss \n",
    "MSE = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(CNN.parameters(), lr=lr)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoints(CNN, model_id, epoch):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_id': model_id,\n",
    "        'CNN_state_dict': CNN.state_dict(),\n",
    "    }, os.path.join('AAV_data/ground_model/'+'CNN' + str(model_id) + \\\n",
    "        '_epoch_{}'.format(epoch)))\n",
    "    return\n",
    "\n",
    "def train(epoch, loss_tr, loss_te, train_full=False):\n",
    "    train_loss_running = 0\n",
    "    for batch, (X_b, y_b) in enumerate(loader):\n",
    "        X_b, y_b = X_b.to(device), y_b.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = CNN(X_b).squeeze(-1)\n",
    "        loss = criterion(y_b, y_pred)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_running += loss.item()\n",
    "    # get avg training loss \n",
    "    train_loss = train_loss_running/batch\n",
    "    # eval\n",
    "    if train_full == False:\n",
    "        with torch.no_grad():\n",
    "            y_pred = CNN(X_test.to(device)).squeeze(-1)\n",
    "            loss_test = MSE(y_pred[:, 0], y_test.to(device)) \n",
    "            print(\"Epoch:\", epoch)\n",
    "            print(\"training loss is:\", train_loss, \n",
    "                  \"; testing MSE is:\", loss_test.item())\n",
    "    else:\n",
    "        print(\"Epoch:\", epoch, \"loss for training is:\", train_loss)\n",
    "    loss_tr.append(train_loss)\n",
    "    loss_te.append(loss_test.item())\n",
    "    return loss_tr, loss_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "training loss is: 2.1255210611762565 ; testing MSE is: 2.670632839202881\n",
      "Epoch: 1\n",
      "training loss is: 1.6882629860007068 ; testing MSE is: 2.4085123538970947\n",
      "Epoch: 2\n",
      "training loss is: 1.635924819777395 ; testing MSE is: 2.3074216842651367\n",
      "Epoch: 3\n",
      "training loss is: 1.6012870977138558 ; testing MSE is: 2.2508997917175293\n",
      "Epoch: 4\n",
      "training loss is: 1.5775697422909363 ; testing MSE is: 2.1630165576934814\n",
      "Epoch: 5\n",
      "training loss is: 1.5632242526472209 ; testing MSE is: 2.1274120807647705\n",
      "Epoch: 6\n",
      "training loss is: 1.5512531548102584 ; testing MSE is: 2.0148847103118896\n",
      "Epoch: 7\n",
      "training loss is: 1.5382396330365415 ; testing MSE is: 1.9992750883102417\n",
      "Epoch: 8\n",
      "training loss is: 1.5296867254957196 ; testing MSE is: 1.9720592498779297\n",
      "Epoch: 9\n",
      "training loss is: 1.5208473279330335 ; testing MSE is: 1.9234211444854736\n",
      "Epoch: 10\n",
      "training loss is: 1.5158523795106162 ; testing MSE is: 1.927497148513794\n",
      "Epoch: 11\n",
      "training loss is: 1.5084619484788833 ; testing MSE is: 1.9655823707580566\n",
      "Epoch: 12\n",
      "training loss is: 1.501272584093075 ; testing MSE is: 1.9416791200637817\n",
      "Epoch: 13\n",
      "training loss is: 1.496401048317064 ; testing MSE is: 1.8604880571365356\n",
      "Epoch: 14\n",
      "training loss is: 1.4901275188790615 ; testing MSE is: 1.9222561120986938\n",
      "Epoch: 15\n",
      "training loss is: 1.4864379177731097 ; testing MSE is: 1.8368127346038818\n",
      "Epoch: 16\n",
      "training loss is: 1.4791619826855396 ; testing MSE is: 1.900986671447754\n",
      "Epoch: 17\n",
      "training loss is: 1.4780604493397567 ; testing MSE is: 1.7933337688446045\n",
      "Epoch: 18\n",
      "training loss is: 1.4718121369905866 ; testing MSE is: 1.7914156913757324\n",
      "Epoch: 19\n",
      "training loss is: 1.4695747545569244 ; testing MSE is: 1.7726837396621704\n",
      "Epoch: 20\n",
      "training loss is: 1.4666695760120538 ; testing MSE is: 1.7519681453704834\n",
      "Epoch: 21\n",
      "training loss is: 1.4617304648478036 ; testing MSE is: 1.7420082092285156\n",
      "Epoch: 22\n",
      "training loss is: 1.4594147267246653 ; testing MSE is: 1.7401912212371826\n",
      "Epoch: 23\n",
      "training loss is: 1.4564382356735923 ; testing MSE is: 1.7438801527023315\n",
      "Epoch: 24\n",
      "training loss is: 1.45275216200952 ; testing MSE is: 1.7888147830963135\n",
      "Epoch: 25\n",
      "training loss is: 1.450926365333465 ; testing MSE is: 1.7537307739257812\n",
      "Epoch: 26\n",
      "training loss is: 1.447154747473227 ; testing MSE is: 1.7768415212631226\n",
      "Epoch: 27\n",
      "training loss is: 1.4457477569410506 ; testing MSE is: 1.6945080757141113\n",
      "Epoch: 28\n",
      "training loss is: 1.4434120832262813 ; testing MSE is: 1.749421238899231\n",
      "Epoch: 29\n",
      "training loss is: 1.4409822011909648 ; testing MSE is: 1.7023844718933105\n",
      "Epoch: 30\n",
      "training loss is: 1.4375624307358417 ; testing MSE is: 1.688301920890808\n",
      "Epoch: 31\n",
      "training loss is: 1.43575120387681 ; testing MSE is: 1.6661354303359985\n",
      "Epoch: 32\n",
      "training loss is: 1.4343136130152523 ; testing MSE is: 1.7360361814498901\n",
      "Epoch: 33\n",
      "training loss is: 1.4337882981191827 ; testing MSE is: 1.7067782878875732\n",
      "Epoch: 34\n",
      "training loss is: 1.4299921021183388 ; testing MSE is: 1.677409291267395\n",
      "Epoch: 35\n",
      "training loss is: 1.427189606436625 ; testing MSE is: 1.6825685501098633\n",
      "Epoch: 36\n",
      "training loss is: 1.4253787623021545 ; testing MSE is: 1.656263828277588\n",
      "Epoch: 37\n",
      "training loss is: 1.4233662784523509 ; testing MSE is: 1.6523754596710205\n",
      "Epoch: 38\n",
      "training loss is: 1.4210954506909355 ; testing MSE is: 1.6854820251464844\n",
      "Epoch: 39\n",
      "training loss is: 1.419898555933327 ; testing MSE is: 1.6646991968154907\n",
      "Epoch: 40\n",
      "training loss is: 1.416706182030831 ; testing MSE is: 1.642804741859436\n",
      "Epoch: 41\n",
      "training loss is: 1.414472434547853 ; testing MSE is: 1.648616909980774\n",
      "Epoch: 42\n",
      "training loss is: 1.413917368964145 ; testing MSE is: 1.6371979713439941\n",
      "Epoch: 43\n",
      "training loss is: 1.4127001520749685 ; testing MSE is: 1.6679679155349731\n",
      "Epoch: 44\n",
      "training loss is: 1.409611632610283 ; testing MSE is: 1.6489148139953613\n",
      "Epoch: 45\n",
      "training loss is: 1.4083661067367108 ; testing MSE is: 1.6392793655395508\n",
      "Epoch: 46\n",
      "training loss is: 1.406946437372422 ; testing MSE is: 1.6368637084960938\n",
      "Epoch: 47\n",
      "training loss is: 1.4049996537809522 ; testing MSE is: 1.624400019645691\n",
      "Epoch: 48\n",
      "training loss is: 1.4024393226140592 ; testing MSE is: 1.6519789695739746\n",
      "Epoch: 49\n",
      "training loss is: 1.4013229330437282 ; testing MSE is: 1.6146663427352905\n",
      "Epoch: 50\n",
      "training loss is: 1.3991694871765452 ; testing MSE is: 1.6136400699615479\n",
      "Epoch: 51\n",
      "training loss is: 1.397899186204202 ; testing MSE is: 1.6238720417022705\n",
      "Epoch: 52\n",
      "training loss is: 1.3958030880599748 ; testing MSE is: 1.6173412799835205\n",
      "Epoch: 53\n",
      "training loss is: 1.394176037518432 ; testing MSE is: 1.6378014087677002\n",
      "Epoch: 54\n",
      "training loss is: 1.394509306672966 ; testing MSE is: 1.6163252592086792\n",
      "Epoch: 55\n",
      "training loss is: 1.3913018435536544 ; testing MSE is: 1.598880410194397\n",
      "Epoch: 56\n",
      "training loss is: 1.3907125781304805 ; testing MSE is: 1.6059365272521973\n",
      "Epoch: 57\n",
      "training loss is: 1.3879520189372099 ; testing MSE is: 1.6117972135543823\n",
      "Epoch: 58\n",
      "training loss is: 1.385612822528584 ; testing MSE is: 1.6336488723754883\n",
      "Epoch: 59\n",
      "training loss is: 1.3840264312573212 ; testing MSE is: 1.6059000492095947\n",
      "Epoch: 60\n",
      "training loss is: 1.3822549878279142 ; testing MSE is: 1.6122270822525024\n",
      "Epoch: 61\n",
      "training loss is: 1.3809314967049644 ; testing MSE is: 1.5979599952697754\n",
      "Epoch: 62\n",
      "training loss is: 1.3799937888026068 ; testing MSE is: 1.6127153635025024\n",
      "Epoch: 63\n",
      "training loss is: 1.3793138802305902 ; testing MSE is: 1.592207670211792\n",
      "Epoch: 64\n",
      "training loss is: 1.376122598288578 ; testing MSE is: 1.6475094556808472\n",
      "Epoch: 65\n",
      "training loss is: 1.375200879862095 ; testing MSE is: 1.6055278778076172\n",
      "Epoch: 66\n",
      "training loss is: 1.3731534600597017 ; testing MSE is: 1.588172197341919\n",
      "Epoch: 67\n",
      "training loss is: 1.3716472767155676 ; testing MSE is: 1.586792230606079\n",
      "Epoch: 68\n",
      "training loss is: 1.3695664085331207 ; testing MSE is: 1.608985424041748\n",
      "Epoch: 69\n",
      "training loss is: 1.366848097417297 ; testing MSE is: 1.5849764347076416\n",
      "Epoch: 70\n",
      "training loss is: 1.3667993563337313 ; testing MSE is: 1.5848093032836914\n",
      "Epoch: 71\n",
      "training loss is: 1.365376407526974 ; testing MSE is: 1.616976022720337\n",
      "Epoch: 72\n",
      "training loss is: 1.3630382574638975 ; testing MSE is: 1.5932477712631226\n",
      "Epoch: 73\n",
      "training loss is: 1.3620704673601587 ; testing MSE is: 1.5831170082092285\n",
      "Epoch: 74\n",
      "training loss is: 1.360469424283691 ; testing MSE is: 1.593800663948059\n",
      "Epoch: 75\n",
      "training loss is: 1.3572342639118644 ; testing MSE is: 1.6246827840805054\n",
      "Epoch: 76\n",
      "training loss is: 1.3572790775326204 ; testing MSE is: 1.5884346961975098\n",
      "Epoch: 77\n",
      "training loss is: 1.3561066887626267 ; testing MSE is: 1.5770782232284546\n",
      "Epoch: 78\n",
      "training loss is: 1.3557486025401912 ; testing MSE is: 1.5806559324264526\n",
      "Epoch: 79\n",
      "training loss is: 1.3520615997897782 ; testing MSE is: 1.5807706117630005\n",
      "Epoch: 80\n",
      "training loss is: 1.3524199839506517 ; testing MSE is: 1.5936484336853027\n",
      "Epoch: 81\n",
      "training loss is: 1.3488073924696802 ; testing MSE is: 1.6327611207962036\n",
      "Epoch: 82\n",
      "training loss is: 1.3488471812408307 ; testing MSE is: 1.6605368852615356\n",
      "Epoch: 83\n",
      "training loss is: 1.3463272827956958 ; testing MSE is: 1.5873239040374756\n",
      "Epoch: 84\n",
      "training loss is: 1.3443865420808154 ; testing MSE is: 1.6051119565963745\n",
      "Epoch: 85\n",
      "training loss is: 1.3441824010052688 ; testing MSE is: 1.6063337326049805\n",
      "Epoch: 86\n",
      "training loss is: 1.3423318309261654 ; testing MSE is: 1.576671838760376\n",
      "Epoch: 87\n",
      "training loss is: 1.3413840875686656 ; testing MSE is: 1.566789984703064\n",
      "Epoch: 88\n",
      "training loss is: 1.3420246948049555 ; testing MSE is: 1.621819019317627\n",
      "Epoch: 89\n",
      "training loss is: 1.3380742576688656 ; testing MSE is: 1.610296607017517\n",
      "Epoch: 90\n",
      "training loss is: 1.3366859727360276 ; testing MSE is: 1.6544189453125\n",
      "Epoch: 91\n",
      "training loss is: 1.3361290796722152 ; testing MSE is: 1.5888144969940186\n",
      "Epoch: 92\n",
      "training loss is: 1.334337376429041 ; testing MSE is: 1.570218563079834\n",
      "Epoch: 93\n",
      "training loss is: 1.3317572620311808 ; testing MSE is: 1.5655044317245483\n",
      "Epoch: 94\n",
      "training loss is: 1.3309830607764244 ; testing MSE is: 1.5734915733337402\n",
      "Epoch: 95\n",
      "training loss is: 1.3294201464435962 ; testing MSE is: 1.6169147491455078\n",
      "Epoch: 96\n",
      "training loss is: 1.3301416385394242 ; testing MSE is: 1.5959138870239258\n",
      "Epoch: 97\n",
      "training loss is: 1.3264106133923592 ; testing MSE is: 1.6077771186828613\n",
      "Epoch: 98\n",
      "training loss is: 1.327647750102948 ; testing MSE is: 1.5626426935195923\n",
      "Epoch: 99\n",
      "training loss is: 1.3237056461710002 ; testing MSE is: 1.5775830745697021\n",
      "Epoch: 100\n",
      "training loss is: 1.32089422017887 ; testing MSE is: 1.573667049407959\n",
      "Epoch: 101\n",
      "training loss is: 1.3219422500469267 ; testing MSE is: 1.5736627578735352\n",
      "Epoch: 102\n",
      "training loss is: 1.3191510335479997 ; testing MSE is: 1.570177435874939\n",
      "Epoch: 103\n",
      "training loss is: 1.3190196838182202 ; testing MSE is: 1.5778608322143555\n",
      "Epoch: 104\n",
      "training loss is: 1.318004229838614 ; testing MSE is: 1.605284333229065\n",
      "Epoch: 105\n",
      "training loss is: 1.31743744740615 ; testing MSE is: 1.5805449485778809\n",
      "Epoch: 106\n",
      "training loss is: 1.314676079438048 ; testing MSE is: 1.6205542087554932\n",
      "Epoch: 107\n",
      "training loss is: 1.3125429401017863 ; testing MSE is: 1.565785527229309\n",
      "Epoch: 108\n",
      "training loss is: 1.3124504375084705 ; testing MSE is: 1.569287657737732\n",
      "Epoch: 109\n",
      "training loss is: 1.3111978339436723 ; testing MSE is: 1.6015655994415283\n",
      "Epoch: 110\n",
      "training loss is: 1.3107122181998208 ; testing MSE is: 1.5786172151565552\n",
      "Epoch: 111\n",
      "training loss is: 1.3089612087348785 ; testing MSE is: 1.6028834581375122\n",
      "Epoch: 112\n",
      "training loss is: 1.3079315219630896 ; testing MSE is: 1.5640867948532104\n",
      "Epoch: 113\n",
      "training loss is: 1.3072253491088304 ; testing MSE is: 1.6030834913253784\n",
      "Epoch: 114\n",
      "training loss is: 1.3064810053722278 ; testing MSE is: 1.5953067541122437\n",
      "Epoch: 115\n",
      "training loss is: 1.30205874193783 ; testing MSE is: 1.5663460493087769\n",
      "Epoch: 116\n",
      "training loss is: 1.3009989748299546 ; testing MSE is: 1.5755256414413452\n",
      "Epoch: 117\n",
      "training loss is: 1.3001451303236515 ; testing MSE is: 1.5786939859390259\n",
      "Epoch: 118\n",
      "training loss is: 1.2994023554694771 ; testing MSE is: 1.5745469331741333\n",
      "Epoch: 119\n",
      "training loss is: 1.2971285876644454 ; testing MSE is: 1.578395962715149\n",
      "Epoch: 120\n",
      "training loss is: 1.2961492908119647 ; testing MSE is: 1.5907899141311646\n",
      "Epoch: 121\n",
      "training loss is: 1.3022041312322168 ; testing MSE is: 1.569651484489441\n",
      "Epoch: 122\n",
      "training loss is: 1.293230220739058 ; testing MSE is: 1.5768859386444092\n",
      "Epoch: 123\n",
      "training loss is: 1.2917272900873702 ; testing MSE is: 1.5970165729522705\n",
      "Epoch: 124\n",
      "training loss is: 1.290976884694052 ; testing MSE is: 1.5657050609588623\n",
      "Epoch: 125\n",
      "training loss is: 1.2889833959881984 ; testing MSE is: 1.577413558959961\n",
      "Epoch: 126\n",
      "training loss is: 1.288900741557478 ; testing MSE is: 1.5765999555587769\n",
      "Epoch: 127\n",
      "training loss is: 1.2887800713182342 ; testing MSE is: 1.574422001838684\n",
      "Epoch: 128\n",
      "training loss is: 1.2912963529569157 ; testing MSE is: 1.6126796007156372\n",
      "Epoch: 129\n",
      "training loss is: 1.283845153675649 ; testing MSE is: 1.5853321552276611\n",
      "Epoch: 130\n",
      "training loss is: 1.2852465325534599 ; testing MSE is: 1.5872632265090942\n",
      "Epoch: 131\n",
      "training loss is: 1.2832976934072133 ; testing MSE is: 1.602822184562683\n",
      "Epoch: 132\n",
      "training loss is: 1.2835199838003428 ; testing MSE is: 1.5702840089797974\n",
      "Epoch: 133\n",
      "training loss is: 1.282205422267127 ; testing MSE is: 1.5965957641601562\n",
      "Epoch: 134\n",
      "training loss is: 1.2780155922745913 ; testing MSE is: 1.6100832223892212\n",
      "Epoch: 135\n",
      "training loss is: 1.2777215743471855 ; testing MSE is: 1.5679634809494019\n",
      "Epoch: 136\n",
      "training loss is: 1.2771215218398853 ; testing MSE is: 1.5878136157989502\n",
      "Epoch: 137\n",
      "training loss is: 1.2761718757969895 ; testing MSE is: 1.576910376548767\n",
      "Epoch: 138\n",
      "training loss is: 1.2778672600538599 ; testing MSE is: 1.5845569372177124\n",
      "Epoch: 139\n",
      "training loss is: 1.2752326370811733 ; testing MSE is: 1.5770975351333618\n",
      "Epoch: 140\n",
      "training loss is: 1.273185131220865 ; testing MSE is: 1.5664777755737305\n",
      "Epoch: 141\n",
      "training loss is: 1.2723594016235211 ; testing MSE is: 1.5893577337265015\n",
      "Epoch: 142\n",
      "training loss is: 1.2722559709467556 ; testing MSE is: 1.577229380607605\n",
      "Epoch: 143\n",
      "training loss is: 1.2700333405778894 ; testing MSE is: 1.5749056339263916\n",
      "Epoch: 144\n",
      "training loss is: 1.2693211408716176 ; testing MSE is: 1.5946325063705444\n",
      "Epoch: 145\n",
      "training loss is: 1.2699560179649343 ; testing MSE is: 1.5915898084640503\n",
      "Epoch: 146\n",
      "training loss is: 1.2672393149027275 ; testing MSE is: 1.5758150815963745\n",
      "Epoch: 147\n",
      "training loss is: 1.2668968311922988 ; testing MSE is: 1.5924838781356812\n",
      "Epoch: 148\n",
      "training loss is: 1.2646238596137522 ; testing MSE is: 1.594183087348938\n",
      "Epoch: 149\n",
      "training loss is: 1.2645470919683681 ; testing MSE is: 1.5936267375946045\n",
      "Epoch: 150\n",
      "training loss is: 1.2625871989160649 ; testing MSE is: 1.5713480710983276\n",
      "Epoch: 151\n",
      "training loss is: 1.261371096582874 ; testing MSE is: 1.5891450643539429\n",
      "Epoch: 152\n",
      "training loss is: 1.2618277260283828 ; testing MSE is: 1.5860792398452759\n",
      "Epoch: 153\n",
      "training loss is: 1.2636876996516504 ; testing MSE is: 1.5879437923431396\n",
      "Epoch: 154\n",
      "training loss is: 1.2585451929362366 ; testing MSE is: 1.6171364784240723\n",
      "Epoch: 155\n",
      "training loss is: 1.2580391618808675 ; testing MSE is: 1.6066834926605225\n",
      "Epoch: 156\n",
      "training loss is: 1.2572410799361564 ; testing MSE is: 1.6008014678955078\n",
      "Epoch: 157\n",
      "training loss is: 1.2580506984743252 ; testing MSE is: 1.6014940738677979\n",
      "Epoch: 158\n",
      "training loss is: 1.2576074477703778 ; testing MSE is: 1.595299482345581\n",
      "Epoch: 159\n",
      "training loss is: 1.2544526036399526 ; testing MSE is: 1.5694198608398438\n",
      "Epoch: 160\n",
      "training loss is: 1.2557125564659304 ; testing MSE is: 1.5894818305969238\n",
      "Epoch: 161\n",
      "training loss is: 1.2523203341245313 ; testing MSE is: 1.5836608409881592\n",
      "Epoch: 162\n",
      "training loss is: 1.2511487181800527 ; testing MSE is: 1.590441346168518\n",
      "Epoch: 163\n",
      "training loss is: 1.2506741394274266 ; testing MSE is: 1.5786575078964233\n",
      "Epoch: 164\n",
      "training loss is: 1.2502107022497086 ; testing MSE is: 1.5869765281677246\n",
      "Epoch: 165\n",
      "training loss is: 1.2503463941312276 ; testing MSE is: 1.5887110233306885\n",
      "Epoch: 166\n",
      "training loss is: 1.2535966555899272 ; testing MSE is: 1.5848910808563232\n",
      "Epoch: 167\n",
      "training loss is: 1.246392890026695 ; testing MSE is: 1.6226589679718018\n",
      "Epoch: 168\n",
      "training loss is: 1.2462990626078072 ; testing MSE is: 1.6170212030410767\n",
      "Epoch: 169\n",
      "training loss is: 1.257272549238517 ; testing MSE is: 1.5835086107254028\n",
      "Epoch: 170\n",
      "training loss is: 1.2453322176573796 ; testing MSE is: 1.5843077898025513\n",
      "Epoch: 171\n",
      "training loss is: 1.2429699983400098 ; testing MSE is: 1.5784891843795776\n",
      "Epoch: 172\n",
      "training loss is: 1.244699618936772 ; testing MSE is: 1.5772373676300049\n",
      "Epoch: 173\n",
      "training loss is: 1.2433791889744157 ; testing MSE is: 1.6075468063354492\n",
      "Epoch: 174\n",
      "training loss is: 1.2405406983614307 ; testing MSE is: 1.6018900871276855\n",
      "Epoch: 175\n",
      "training loss is: 1.24072953198068 ; testing MSE is: 1.5904302597045898\n",
      "Epoch: 176\n",
      "training loss is: 1.2416853669866559 ; testing MSE is: 1.579885482788086\n",
      "Epoch: 177\n",
      "training loss is: 1.240405456015938 ; testing MSE is: 1.589327335357666\n",
      "Epoch: 178\n",
      "training loss is: 1.23891769148208 ; testing MSE is: 1.587702989578247\n",
      "Epoch: 179\n",
      "training loss is: 1.2372538104420197 ; testing MSE is: 1.607047200202942\n",
      "Epoch: 180\n",
      "training loss is: 1.2364380945521771 ; testing MSE is: 1.5831389427185059\n",
      "Epoch: 181\n",
      "training loss is: 1.234390846356898 ; testing MSE is: 1.5922744274139404\n",
      "Epoch: 182\n",
      "training loss is: 1.236637525037885 ; testing MSE is: 1.6001487970352173\n",
      "Epoch: 183\n",
      "training loss is: 1.2323840218960476 ; testing MSE is: 1.5898942947387695\n",
      "Epoch: 184\n",
      "training loss is: 1.2351237940330424 ; testing MSE is: 1.5989478826522827\n",
      "Epoch: 185\n",
      "training loss is: 1.233439420568485 ; testing MSE is: 1.5946682691574097\n",
      "Epoch: 186\n",
      "training loss is: 1.2351459234656175 ; testing MSE is: 1.6802828311920166\n",
      "Epoch: 187\n",
      "training loss is: 1.2341641346217898 ; testing MSE is: 1.5994185209274292\n",
      "Epoch: 188\n",
      "training loss is: 1.2287731197785856 ; testing MSE is: 1.580322265625\n",
      "Epoch: 189\n",
      "training loss is: 1.2293497679243726 ; testing MSE is: 1.5871378183364868\n",
      "Epoch: 190\n",
      "training loss is: 1.2309121392020799 ; testing MSE is: 1.6013292074203491\n",
      "Epoch: 191\n",
      "training loss is: 1.228824736595493 ; testing MSE is: 1.6300605535507202\n",
      "Epoch: 192\n",
      "training loss is: 1.2277730177255985 ; testing MSE is: 1.6078959703445435\n",
      "Epoch: 193\n",
      "training loss is: 1.2275661439509005 ; testing MSE is: 1.5895153284072876\n",
      "Epoch: 194\n",
      "training loss is: 1.2241001155010158 ; testing MSE is: 1.583243727684021\n",
      "Epoch: 195\n",
      "training loss is: 1.226601055429806 ; testing MSE is: 1.6347399950027466\n",
      "Epoch: 196\n",
      "training loss is: 1.2242054088865202 ; testing MSE is: 1.5891907215118408\n",
      "Epoch: 197\n",
      "training loss is: 1.2237279663130027 ; testing MSE is: 1.5915167331695557\n",
      "Epoch: 198\n",
      "training loss is: 1.2442899196280186 ; testing MSE is: 1.6004661321640015\n",
      "Epoch: 199\n",
      "training loss is: 1.2270837734383166 ; testing MSE is: 1.5928539037704468\n",
      "Epoch: 200\n",
      "training loss is: 1.2211228843942645 ; testing MSE is: 1.5999265909194946\n",
      "Epoch: 201\n",
      "training loss is: 1.2228322010036892 ; testing MSE is: 1.606892704963684\n",
      "Epoch: 202\n",
      "training loss is: 1.2175857838068376 ; testing MSE is: 1.596006989479065\n",
      "Epoch: 203\n",
      "training loss is: 1.2203463569898185 ; testing MSE is: 1.5978702306747437\n",
      "Epoch: 204\n",
      "training loss is: 1.220586389048849 ; testing MSE is: 1.597943663597107\n",
      "Epoch: 205\n",
      "training loss is: 1.2166487562707273 ; testing MSE is: 1.6026912927627563\n",
      "Epoch: 206\n",
      "training loss is: 1.2168851069586715 ; testing MSE is: 1.5954259634017944\n",
      "Epoch: 207\n",
      "training loss is: 1.2193008967348047 ; testing MSE is: 1.594730257987976\n",
      "Epoch: 208\n",
      "training loss is: 1.2251388660789724 ; testing MSE is: 1.6019443273544312\n",
      "Epoch: 209\n",
      "training loss is: 1.2122585739977498 ; testing MSE is: 1.6233876943588257\n",
      "Epoch: 210\n",
      "training loss is: 1.2159343477587612 ; testing MSE is: 1.603505253791809\n",
      "Epoch: 211\n",
      "training loss is: 1.212397032747228 ; testing MSE is: 1.6322585344314575\n",
      "Epoch: 212\n",
      "training loss is: 1.2111746973197797 ; testing MSE is: 1.5879334211349487\n",
      "Epoch: 213\n",
      "training loss is: 1.2135587381689172 ; testing MSE is: 1.586302399635315\n",
      "Epoch: 214\n",
      "training loss is: 1.2117255832443536 ; testing MSE is: 1.6209588050842285\n",
      "Epoch: 215\n",
      "training loss is: 1.2099177058611283 ; testing MSE is: 1.6043294668197632\n",
      "Epoch: 216\n",
      "training loss is: 1.209886467600954 ; testing MSE is: 1.5970882177352905\n",
      "Epoch: 217\n",
      "training loss is: 1.2114728228805076 ; testing MSE is: 1.6085869073867798\n",
      "Epoch: 218\n",
      "training loss is: 1.2096535453670902 ; testing MSE is: 1.6005229949951172\n",
      "Epoch: 219\n",
      "training loss is: 1.2094056143784422 ; testing MSE is: 1.6033438444137573\n",
      "Epoch: 220\n",
      "training loss is: 1.2075902846765043 ; testing MSE is: 1.6031516790390015\n",
      "Epoch: 221\n",
      "training loss is: 1.20614189842178 ; testing MSE is: 1.5869765281677246\n",
      "Epoch: 222\n",
      "training loss is: 1.207558583272131 ; testing MSE is: 1.635864496231079\n",
      "Epoch: 223\n",
      "training loss is: 1.2063770342517544 ; testing MSE is: 1.608324408531189\n",
      "Epoch: 224\n",
      "training loss is: 1.2043640315108755 ; testing MSE is: 1.5927157402038574\n",
      "Epoch: 225\n",
      "training loss is: 1.2026994305094478 ; testing MSE is: 1.595533013343811\n",
      "Epoch: 226\n",
      "training loss is: 1.2043742111448204 ; testing MSE is: 1.59961998462677\n",
      "Epoch: 227\n",
      "training loss is: 1.2070287811552647 ; testing MSE is: 1.610015869140625\n",
      "Epoch: 228\n",
      "training loss is: 1.2025890033241695 ; testing MSE is: 1.5984431505203247\n",
      "Epoch: 229\n",
      "training loss is: 1.2003168765545569 ; testing MSE is: 1.5987735986709595\n",
      "Epoch: 230\n",
      "training loss is: 1.1994018449552708 ; testing MSE is: 1.609984040260315\n",
      "Epoch: 231\n",
      "training loss is: 1.1987038265336118 ; testing MSE is: 1.616753101348877\n",
      "Epoch: 232\n",
      "training loss is: 1.198909560782811 ; testing MSE is: 1.599786639213562\n",
      "Epoch: 233\n",
      "training loss is: 1.1995283949849955 ; testing MSE is: 1.6346193552017212\n",
      "Epoch: 234\n",
      "training loss is: 1.1989337564956073 ; testing MSE is: 1.611741304397583\n",
      "Epoch: 235\n",
      "training loss is: 1.1955023463894938 ; testing MSE is: 1.597402572631836\n",
      "Epoch: 236\n",
      "training loss is: 1.1946356609824034 ; testing MSE is: 1.6005754470825195\n",
      "Epoch: 237\n",
      "training loss is: 1.1947872233424723 ; testing MSE is: 1.62041175365448\n",
      "Epoch: 238\n",
      "training loss is: 1.1970441630520827 ; testing MSE is: 1.6150721311569214\n",
      "Epoch: 239\n",
      "training loss is: 1.1961663200878996 ; testing MSE is: 1.5978091955184937\n",
      "Epoch: 240\n",
      "training loss is: 1.1953609804510223 ; testing MSE is: 1.6096718311309814\n",
      "Epoch: 241\n",
      "training loss is: 1.1950216178025832 ; testing MSE is: 1.639543056488037\n",
      "Epoch: 242\n",
      "training loss is: 1.1905473493580119 ; testing MSE is: 1.6111701726913452\n",
      "Epoch: 243\n",
      "training loss is: 1.1911320289965206 ; testing MSE is: 1.6173155307769775\n",
      "Epoch: 244\n",
      "training loss is: 1.1932747984678613 ; testing MSE is: 1.6130784749984741\n",
      "Epoch: 245\n",
      "training loss is: 1.1913093915195927 ; testing MSE is: 1.610832929611206\n",
      "Epoch: 246\n",
      "training loss is: 1.2033320226167377 ; testing MSE is: 1.6703845262527466\n",
      "Epoch: 247\n",
      "training loss is: 1.2114467447885917 ; testing MSE is: 1.6119999885559082\n",
      "Epoch: 248\n",
      "training loss is: 1.190049021037171 ; testing MSE is: 1.612267255783081\n",
      "Epoch: 249\n",
      "training loss is: 1.1901816161055314 ; testing MSE is: 1.6183949708938599\n",
      "Epoch: 250\n",
      "training loss is: 1.1862610077027067 ; testing MSE is: 1.6032198667526245\n",
      "Epoch: 251\n",
      "training loss is: 1.1899842700018821 ; testing MSE is: 1.630332112312317\n",
      "Epoch: 252\n",
      "training loss is: 1.184788746438698 ; testing MSE is: 1.6156015396118164\n",
      "Epoch: 253\n",
      "training loss is: 1.1900585978841713 ; testing MSE is: 1.6199415922164917\n",
      "Epoch: 254\n",
      "training loss is: 1.1869452694062657 ; testing MSE is: 1.604711651802063\n",
      "Epoch: 255\n",
      "training loss is: 1.1859155872553206 ; testing MSE is: 1.6195062398910522\n",
      "Epoch: 256\n",
      "training loss is: 1.1879943351911786 ; testing MSE is: 1.6190030574798584\n",
      "Epoch: 257\n",
      "training loss is: 1.1825612598174327 ; testing MSE is: 1.6185396909713745\n",
      "Epoch: 258\n",
      "training loss is: 1.1877394823905922 ; testing MSE is: 1.6006124019622803\n",
      "Epoch: 259\n",
      "training loss is: 1.1850375216003841 ; testing MSE is: 1.6133984327316284\n",
      "Epoch: 260\n",
      "training loss is: 1.1848121404563041 ; testing MSE is: 1.6277670860290527\n",
      "Epoch: 261\n",
      "training loss is: 1.180534719530583 ; testing MSE is: 1.6131082773208618\n",
      "Epoch: 262\n",
      "training loss is: 1.18074538409286 ; testing MSE is: 1.6139659881591797\n",
      "Epoch: 263\n",
      "training loss is: 1.1793533999414567 ; testing MSE is: 1.6344634294509888\n",
      "Epoch: 264\n",
      "training loss is: 1.181523060052527 ; testing MSE is: 1.6148686408996582\n",
      "Epoch: 265\n",
      "training loss is: 1.1764144832175623 ; testing MSE is: 1.6467373371124268\n",
      "Epoch: 266\n",
      "training loss is: 1.1797595924961448 ; testing MSE is: 1.6279056072235107\n",
      "Epoch: 267\n",
      "training loss is: 1.177730207634854 ; testing MSE is: 1.6432781219482422\n",
      "Epoch: 268\n",
      "training loss is: 1.1811042325425454 ; testing MSE is: 1.6227855682373047\n",
      "Epoch: 269\n",
      "training loss is: 1.1801423618244073 ; testing MSE is: 1.6041514873504639\n",
      "Epoch: 270\n",
      "training loss is: 1.1791899701100834 ; testing MSE is: 1.6204966306686401\n",
      "Epoch: 271\n",
      "training loss is: 1.176314513171211 ; testing MSE is: 1.6190937757492065\n",
      "Epoch: 272\n",
      "training loss is: 1.1895238223404836 ; testing MSE is: 1.6312648057937622\n",
      "Epoch: 273\n",
      "training loss is: 1.1751067127984753 ; testing MSE is: 1.6178432703018188\n",
      "Epoch: 274\n",
      "training loss is: 1.1763125225202118 ; testing MSE is: 1.6141389608383179\n",
      "Epoch: 275\n",
      "training loss is: 1.1767449722775016 ; testing MSE is: 1.6076425313949585\n",
      "Epoch: 276\n",
      "training loss is: 1.1814281858217666 ; testing MSE is: 1.6220977306365967\n",
      "Epoch: 277\n",
      "training loss is: 1.1764473603087164 ; testing MSE is: 1.6251788139343262\n",
      "Epoch: 278\n",
      "training loss is: 1.173753527285873 ; testing MSE is: 1.630127191543579\n",
      "Epoch: 279\n",
      "training loss is: 1.1729872422994965 ; testing MSE is: 1.6242668628692627\n",
      "Epoch: 280\n",
      "training loss is: 1.1746489829138707 ; testing MSE is: 1.628941297531128\n",
      "Epoch: 281\n",
      "training loss is: 1.172038565022847 ; testing MSE is: 1.6152194738388062\n",
      "Epoch: 282\n",
      "training loss is: 1.1717082710557778 ; testing MSE is: 1.6273924112319946\n",
      "Epoch: 283\n",
      "training loss is: 1.176410674285753 ; testing MSE is: 1.624495029449463\n",
      "Epoch: 284\n",
      "training loss is: 1.1697382521663249 ; testing MSE is: 1.6138122081756592\n",
      "Epoch: 285\n",
      "training loss is: 1.1701504962457872 ; testing MSE is: 1.6324129104614258\n",
      "Epoch: 286\n",
      "training loss is: 1.1718800114533978 ; testing MSE is: 1.6500709056854248\n",
      "Epoch: 287\n",
      "training loss is: 1.1682527227642525 ; testing MSE is: 1.6142677068710327\n",
      "Epoch: 288\n",
      "training loss is: 1.1684692493543176 ; testing MSE is: 1.6183956861495972\n",
      "Epoch: 289\n",
      "training loss is: 1.180114506954489 ; testing MSE is: 1.617462396621704\n",
      "Epoch: 290\n",
      "training loss is: 1.1734082676353699 ; testing MSE is: 1.6299715042114258\n",
      "Epoch: 291\n",
      "training loss is: 1.1671938809273423 ; testing MSE is: 1.6071343421936035\n",
      "Epoch: 292\n",
      "training loss is: 1.1685756017185038 ; testing MSE is: 1.672215223312378\n",
      "Epoch: 293\n",
      "training loss is: 1.1671139716169403 ; testing MSE is: 1.6215710639953613\n",
      "Epoch: 294\n",
      "training loss is: 1.1650238021423942 ; testing MSE is: 1.6215760707855225\n",
      "Epoch: 295\n",
      "training loss is: 1.170428001397365 ; testing MSE is: 1.6308889389038086\n",
      "Epoch: 296\n",
      "training loss is: 1.167512574372217 ; testing MSE is: 1.6219590902328491\n",
      "Epoch: 297\n",
      "training loss is: 1.1692993328886725 ; testing MSE is: 1.631365418434143\n",
      "Epoch: 298\n",
      "training loss is: 1.1664716037120113 ; testing MSE is: 1.6318660974502563\n",
      "Epoch: 299\n",
      "training loss is: 1.1642881346969822 ; testing MSE is: 1.6305760145187378\n"
     ]
    }
   ],
   "source": [
    "loss_tr, loss_te = [], []\n",
    "for e in range(300):\n",
    "    loss_tr, loss_te = train(e, loss_tr, loss_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.61016524, 3.10935128, 3.34050274, 3.65482473, 3.64157796,\n",
       "        3.53691149, 3.49341369, 3.43271708, 3.4210366 , 3.63521731]),\n",
       " tensor([3.5584, 3.1370, 3.5275, 3.5782, 3.7308, 3.3761, 3.7312, 3.4574, 3.4884,\n",
       "         3.7136]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNNs = load_GFP_ground_CNNs(n_models=2, train_epoch=300)\n",
    "y_pred = ensemble_infer(CNNs, X_test[:10])\n",
    "y_pred, y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oracle model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# generate oracles for n_experiment \n",
    "n_experiment = 10\n",
    "train_size = 512 # use 256 sequence with fitness values for each experiment\n",
    "##################################################\n",
    "seed_everything()\n",
    "df = pd.read_csv('AAV_data/AAV_library.csv')\n",
    "X, y, seqs = get_AAV_X_y_aa(df, large_only=False, return_str=True)\n",
    "WT_AAV_encoding = torch.Tensor(\n",
    "    one_hot_aav_mutation_seq(WT_AAV2[AAV_START:AAV_END]).argmax(-1))\n",
    "# since there are different fitness measurement for the same sequence\n",
    "X = get_unique_X(X)\n",
    "groundtruth_models = load_AAV_ground_CNNs(n_models=8, train_epoch=300)\n",
    "y_gt = ensemble_infer(groundtruth_models, torch.tensor(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain oracle trained with only single-mutation sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.5804 - val_loss: 1.7511\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3081 - val_loss: 1.3486\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2220 - val_loss: 1.3367\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0722 - val_loss: 1.5520\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.0035 - val_loss: 1.5852\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.0021 - val_loss: 1.6198\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.9437 - val_loss: 1.4193\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 0.9515 - val_loss: 1.4145\n",
      "Epoch 00008: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.2141 - val_loss: 1.3681\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.0636 - val_loss: 1.4689\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0345 - val_loss: 1.4990\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0093 - val_loss: 1.4161\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.0317 - val_loss: 1.3373\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9711 - val_loss: 1.4538\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.9066 - val_loss: 1.8384\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 0.9722 - val_loss: 1.5260\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 0.8843 - val_loss: 1.5709\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 0.8443 - val_loss: 1.4836\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.3531 - val_loss: 1.4746\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1312 - val_loss: 1.3864\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0769 - val_loss: 1.5464\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0339 - val_loss: 1.5709\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.9985 - val_loss: 1.4479\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9598 - val_loss: 1.4718\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.9357 - val_loss: 1.5771\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.0860 - val_loss: 1.4875\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.0921 - val_loss: 1.6097\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0701 - val_loss: 1.3740\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0419 - val_loss: 1.4209\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.9828 - val_loss: 1.4983\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9441 - val_loss: 1.5388\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.9310 - val_loss: 1.5950\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 0.8984 - val_loss: 1.4891\n",
      "Epoch 00008: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.3366 - val_loss: 1.5714\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1343 - val_loss: 1.4274\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0699 - val_loss: 1.6946\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0386 - val_loss: 1.5588\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.0117 - val_loss: 1.5078\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9833 - val_loss: 1.5578\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.9362 - val_loss: 1.6062\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.6092 - val_loss: 1.4336\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.4191 - val_loss: 1.2430\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2997 - val_loss: 1.2032\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.2213 - val_loss: 1.0973\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1878 - val_loss: 1.0429\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.1280 - val_loss: 1.0389\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.1039 - val_loss: 1.0450\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0925 - val_loss: 1.0273\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0519 - val_loss: 1.0296\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.0249 - val_loss: 1.0160\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.9755 - val_loss: 1.0255\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.9663 - val_loss: 1.0989\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.9974 - val_loss: 1.0591\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.9029 - val_loss: 0.9989\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.8617 - val_loss: 0.9981\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.7797 - val_loss: 1.0505\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 0.7472 - val_loss: 1.0230\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 0.6996 - val_loss: 0.9633\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 0.6337 - val_loss: 1.0547\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 0.5362 - val_loss: 1.1987\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 0.5136 - val_loss: 0.9921\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 0.3781 - val_loss: 1.3536\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 0.3254 - val_loss: 1.0012\n",
      "Epoch 00023: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.5289 - val_loss: 1.4566\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.4046 - val_loss: 1.1984\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2862 - val_loss: 1.1079\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1831 - val_loss: 1.0941\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1681 - val_loss: 1.0806\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.1393 - val_loss: 1.0669\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.1112 - val_loss: 1.0627\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0755 - val_loss: 1.0567\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0569 - val_loss: 1.0468\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.0120 - val_loss: 1.0359\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.9752 - val_loss: 1.0247\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.9383 - val_loss: 1.0393\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.9086 - val_loss: 1.0146\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.8358 - val_loss: 1.0873\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.7962 - val_loss: 1.1589\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.8979 - val_loss: 1.1052\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 0.8194 - val_loss: 1.0636\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 0.6392 - val_loss: 1.2227\n",
      "Epoch 00018: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.4233 - val_loss: 1.2383\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2541 - val_loss: 1.2075\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2236 - val_loss: 1.1249\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1647 - val_loss: 1.1020\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1496 - val_loss: 1.0918\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.0992 - val_loss: 1.0887\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0767 - val_loss: 1.0663\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0387 - val_loss: 1.0625\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0203 - val_loss: 1.0682\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 0.9828 - val_loss: 1.0506\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.9488 - val_loss: 1.1332\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.9024 - val_loss: 1.0284\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.8361 - val_loss: 1.0243\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.7828 - val_loss: 1.0749\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.7463 - val_loss: 1.8257\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.0146 - val_loss: 1.1884\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 0.9956 - val_loss: 1.1772\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 0.8406 - val_loss: 0.9908\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 0.6018 - val_loss: 1.3613\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 0.5418 - val_loss: 1.3840\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 0.4923 - val_loss: 1.1363\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 0.4471 - val_loss: 1.0943\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 0.3140 - val_loss: 1.4749\n",
      "Epoch 00023: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.2742 - val_loss: 1.0916\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2240 - val_loss: 1.0508\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2269 - val_loss: 1.1309\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1980 - val_loss: 1.0922\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1349 - val_loss: 1.0147\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.1084 - val_loss: 1.0338\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0821 - val_loss: 1.0306\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0448 - val_loss: 1.0003\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0055 - val_loss: 0.9855\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 0.9597 - val_loss: 0.9910\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.9790 - val_loss: 1.0303\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.9360 - val_loss: 0.9814\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.8314 - val_loss: 0.9894\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.7998 - val_loss: 0.9866\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.7417 - val_loss: 1.0332\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.7077 - val_loss: 0.9176\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 0.6426 - val_loss: 1.0126\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 0.6443 - val_loss: 1.3439\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 0.6386 - val_loss: 0.8833\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 0.4642 - val_loss: 1.0462\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 0.4393 - val_loss: 1.2889\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 0.2964 - val_loss: 1.0006\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 0.1734 - val_loss: 1.4592\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 0.1939 - val_loss: 1.9362\n",
      "Epoch 00024: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.4157 - val_loss: 1.2090\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2616 - val_loss: 1.2208\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2336 - val_loss: 1.1348\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1624 - val_loss: 1.0878\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1306 - val_loss: 1.0860\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.1196 - val_loss: 1.0509\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0785 - val_loss: 1.0374\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0296 - val_loss: 1.0274\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0065 - val_loss: 1.1696\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.0100 - val_loss: 1.0666\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.9531 - val_loss: 1.0401\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.8777 - val_loss: 1.0307\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.9130 - val_loss: 1.1862\n",
      "Epoch 00013: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.4328 - val_loss: 1.3392\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3916 - val_loss: 1.1341\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2112 - val_loss: 0.9980\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1837 - val_loss: 0.9759\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1155 - val_loss: 1.0018\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.0959 - val_loss: 0.9846\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0654 - val_loss: 0.9977\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0469 - val_loss: 0.9815\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0245 - val_loss: 0.9883\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.6269 - val_loss: 1.3171\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3373 - val_loss: 1.2451\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.3088 - val_loss: 1.2145\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.2203 - val_loss: 1.0719\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1291 - val_loss: 1.0754\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.1208 - val_loss: 1.0035\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0736 - val_loss: 1.0491\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0960 - val_loss: 1.0388\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0759 - val_loss: 1.0165\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 0.9888 - val_loss: 0.9954\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.9514 - val_loss: 1.0076\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.9161 - val_loss: 1.0670\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.9626 - val_loss: 1.0618\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.0173 - val_loss: 1.0086\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.9713 - val_loss: 1.0111\n",
      "Epoch 00015: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.4363 - val_loss: 1.3220\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3188 - val_loss: 1.1501\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2348 - val_loss: 1.0434\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1421 - val_loss: 0.9921\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1316 - val_loss: 1.0515\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.0998 - val_loss: 1.0053\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0653 - val_loss: 0.9830\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0666 - val_loss: 1.0118\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0171 - val_loss: 1.0008\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.0013 - val_loss: 0.9846\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.9674 - val_loss: 0.9798\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.9507 - val_loss: 1.0064\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.8985 - val_loss: 0.9826\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.8499 - val_loss: 0.9974\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.8254 - val_loss: 1.0246\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.7866 - val_loss: 1.0953\n",
      "Epoch 00016: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.4388 - val_loss: 1.1304\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3029 - val_loss: 1.2423\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2376 - val_loss: 1.0627\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1778 - val_loss: 0.9961\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.2189 - val_loss: 0.9891\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.1394 - val_loss: 0.9962\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.1383 - val_loss: 1.0090\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0803 - val_loss: 0.9843\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0260 - val_loss: 0.9757\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.0213 - val_loss: 0.9659\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.9651 - val_loss: 0.9517\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.9375 - val_loss: 0.9563\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.9024 - val_loss: 0.9741\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.8518 - val_loss: 0.9717\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.8170 - val_loss: 0.9871\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.7535 - val_loss: 0.9550\n",
      "Epoch 00016: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.2879 - val_loss: 1.1033\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2279 - val_loss: 1.0273\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2048 - val_loss: 1.0790\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1330 - val_loss: 0.9797\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.0743 - val_loss: 0.9793\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.0447 - val_loss: 1.0011\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0294 - val_loss: 0.9660\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.1016 - val_loss: 1.1031\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0612 - val_loss: 1.0232\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 0.9520 - val_loss: 0.9660\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.9481 - val_loss: 1.0976\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.8890 - val_loss: 0.9512\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.8282 - val_loss: 0.9841\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.7744 - val_loss: 0.9476\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.7042 - val_loss: 1.0308\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.6594 - val_loss: 1.0622\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 0.6222 - val_loss: 1.0306\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 0.5781 - val_loss: 1.0602\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 0.5322 - val_loss: 1.1191\n",
      "Epoch 00019: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.4974 - val_loss: 1.3741\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2957 - val_loss: 1.2901\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2448 - val_loss: 1.2952\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1682 - val_loss: 1.2259\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1516 - val_loss: 1.2596\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.0922 - val_loss: 1.2555\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0789 - val_loss: 1.2343\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0371 - val_loss: 1.2325\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0026 - val_loss: 1.3455\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.3344 - val_loss: 1.2299\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2115 - val_loss: 1.1830\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.1839 - val_loss: 1.1841\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1705 - val_loss: 1.2172\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1338 - val_loss: 1.1794\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.0725 - val_loss: 1.3286\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0783 - val_loss: 1.1907\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0283 - val_loss: 1.1789\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 0.9922 - val_loss: 1.1837\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.0430 - val_loss: 1.2355\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.9664 - val_loss: 1.2089\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.8944 - val_loss: 1.4815\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.8980 - val_loss: 1.1785\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.8362 - val_loss: 1.2186\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.8133 - val_loss: 1.3473\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.7535 - val_loss: 1.7277\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 0.6968 - val_loss: 1.5920\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 0.6662 - val_loss: 1.3700\n",
      "Epoch 00018: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.6402 - val_loss: 1.6323\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.5464 - val_loss: 1.3888\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.3073 - val_loss: 1.2323\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.2380 - val_loss: 1.2436\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1566 - val_loss: 1.1623\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.1381 - val_loss: 1.2261\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.1124 - val_loss: 1.1619\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0725 - val_loss: 1.2098\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0521 - val_loss: 1.1663\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.0158 - val_loss: 1.1910\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.9954 - val_loss: 1.1528\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.9496 - val_loss: 1.1847\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.9415 - val_loss: 1.2261\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.9153 - val_loss: 1.1605\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.8658 - val_loss: 1.2058\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.7976 - val_loss: 1.2904\n",
      "Epoch 00016: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.4896 - val_loss: 1.5364\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3136 - val_loss: 1.2613\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2543 - val_loss: 1.2178\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1813 - val_loss: 1.2038\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1315 - val_loss: 1.1889\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.1230 - val_loss: 1.2099\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0973 - val_loss: 1.1872\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0636 - val_loss: 1.2302\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0332 - val_loss: 1.1713\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.0044 - val_loss: 1.2691\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.9941 - val_loss: 1.2393\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.9441 - val_loss: 1.1928\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.8986 - val_loss: 1.3253\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.8749 - val_loss: 1.2720\n",
      "Epoch 00014: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.2813 - val_loss: 1.2138\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2302 - val_loss: 1.1795\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2835 - val_loss: 1.2262\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.2317 - val_loss: 1.1729\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1231 - val_loss: 1.2079\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.0849 - val_loss: 1.1667\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0488 - val_loss: 1.1869\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0191 - val_loss: 1.1460\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0688 - val_loss: 1.1745\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.0208 - val_loss: 1.1321\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.9227 - val_loss: 1.2358\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.8780 - val_loss: 1.3707\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.8182 - val_loss: 1.2406\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.7717 - val_loss: 1.2064\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.7392 - val_loss: 1.1705\n",
      "Epoch 00015: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.3851 - val_loss: 1.5542\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2447 - val_loss: 1.4977\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2123 - val_loss: 1.5834\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1736 - val_loss: 1.5668\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1506 - val_loss: 1.5221\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.1313 - val_loss: 1.5714\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.1653 - val_loss: 1.4514\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.1218 - val_loss: 1.5055\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0785 - val_loss: 1.5964\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.0699 - val_loss: 1.7370\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.0078 - val_loss: 1.6534\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.9563 - val_loss: 1.7705\n",
      "Epoch 00012: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.2804 - val_loss: 1.5107\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2518 - val_loss: 1.5266\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2169 - val_loss: 1.4943\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1563 - val_loss: 1.5045\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1343 - val_loss: 1.4903\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.1100 - val_loss: 1.5124\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.1012 - val_loss: 1.5793\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0787 - val_loss: 1.5738\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0429 - val_loss: 1.6301\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.0206 - val_loss: 1.6163\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.5152 - val_loss: 1.6243\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3629 - val_loss: 1.4753\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.3257 - val_loss: 1.4497\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1968 - val_loss: 1.5388\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1794 - val_loss: 1.6953\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.1382 - val_loss: 1.5327\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0842 - val_loss: 1.4773\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0817 - val_loss: 1.4626\n",
      "Epoch 00008: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.3720 - val_loss: 1.4693\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2419 - val_loss: 1.4310\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.1859 - val_loss: 1.5086\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1679 - val_loss: 1.7183\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1156 - val_loss: 1.5176\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.0772 - val_loss: 1.5424\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0953 - val_loss: 1.5709\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 2.1038 - val_loss: 1.7400\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.4102 - val_loss: 1.4946\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.3197 - val_loss: 1.4831\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.3142 - val_loss: 1.4536\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.2438 - val_loss: 1.5065\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.1704 - val_loss: 1.5327\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.1701 - val_loss: 1.5514\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.1271 - val_loss: 1.6249\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0801 - val_loss: 1.5751\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.3541 - val_loss: 1.7628\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1359 - val_loss: 1.3960\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0673 - val_loss: 1.5694\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0089 - val_loss: 1.6753\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.9589 - val_loss: 1.6608\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9215 - val_loss: 1.6006\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.9104 - val_loss: 1.5689\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.5614 - val_loss: 2.0597\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2018 - val_loss: 1.3638\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.1539 - val_loss: 1.3393\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0502 - val_loss: 1.5481\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.9689 - val_loss: 1.5092\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9501 - val_loss: 1.8080\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.9176 - val_loss: 1.5961\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 0.8716 - val_loss: 1.7370\n",
      "Epoch 00008: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.4405 - val_loss: 1.9718\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2616 - val_loss: 1.3682\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.1572 - val_loss: 1.3754\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0334 - val_loss: 1.7835\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.9641 - val_loss: 1.6406\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9210 - val_loss: 1.7803\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.9250 - val_loss: 1.5990\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.5922 - val_loss: 1.9408\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3951 - val_loss: 1.4333\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2046 - val_loss: 1.3465\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1051 - val_loss: 1.6335\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.9695 - val_loss: 1.6338\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9321 - val_loss: 1.8885\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.9037 - val_loss: 1.7303\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 0.8449 - val_loss: 1.6707\n",
      "Epoch 00008: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.1466 - val_loss: 1.4451\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.0438 - val_loss: 1.6516\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0444 - val_loss: 1.4508\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0183 - val_loss: 1.5396\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.9629 - val_loss: 1.4605\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9667 - val_loss: 1.5756\n",
      "Epoch 00006: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.7006 - val_loss: 1.4803\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.4091 - val_loss: 1.1996\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.3149 - val_loss: 1.2180\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.2508 - val_loss: 1.1390\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1838 - val_loss: 1.0375\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.1338 - val_loss: 1.0174\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.1134 - val_loss: 1.0388\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0816 - val_loss: 1.0200\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0721 - val_loss: 1.0278\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.0303 - val_loss: 1.0271\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.0006 - val_loss: 1.0060\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.9626 - val_loss: 1.0853\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.9170 - val_loss: 1.0933\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.9427 - val_loss: 1.1234\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.9046 - val_loss: 1.0418\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.8987 - val_loss: 1.1177\n",
      "Epoch 00016: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.3344 - val_loss: 1.1125\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2279 - val_loss: 1.0078\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2127 - val_loss: 1.0044\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1592 - val_loss: 1.0497\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1366 - val_loss: 0.9860\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.1006 - val_loss: 0.9690\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0645 - val_loss: 0.9730\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0407 - val_loss: 0.9957\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0310 - val_loss: 1.0116\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.0338 - val_loss: 0.9599\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.9587 - val_loss: 0.9568\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.9062 - val_loss: 0.9536\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.8890 - val_loss: 0.9321\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.9137 - val_loss: 1.0313\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.9126 - val_loss: 0.9409\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.8395 - val_loss: 0.9997\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 0.7281 - val_loss: 0.9302\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 0.6886 - val_loss: 0.9383\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 0.6093 - val_loss: 1.0684\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 0.5260 - val_loss: 0.9102\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 0.4612 - val_loss: 1.1374\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 0.4547 - val_loss: 2.0320\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 0.7550 - val_loss: 0.9943\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 0.7308 - val_loss: 0.9926\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 0.4408 - val_loss: 1.2692\n",
      "Epoch 00025: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.3497 - val_loss: 1.0876\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2346 - val_loss: 1.0714\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.1874 - val_loss: 1.0720\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1554 - val_loss: 1.0206\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1303 - val_loss: 1.0182\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.0943 - val_loss: 1.0756\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0941 - val_loss: 1.0367\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0495 - val_loss: 1.0164\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0916 - val_loss: 1.0711\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.0477 - val_loss: 1.0328\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.9700 - val_loss: 0.9940\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.9157 - val_loss: 1.0032\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.8865 - val_loss: 1.0046\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.8341 - val_loss: 1.0545\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.8534 - val_loss: 0.9836\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.9017 - val_loss: 1.0202\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 0.7881 - val_loss: 1.1422\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 0.6912 - val_loss: 1.1992\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 0.6195 - val_loss: 1.2348\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 0.6221 - val_loss: 0.9861\n",
      "Epoch 00020: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.9304 - val_loss: 1.5066\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6273 - val_loss: 1.4387\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.4050 - val_loss: 1.2828\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.3427 - val_loss: 1.2478\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.2625 - val_loss: 1.1203\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.1620 - val_loss: 1.0494\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.1232 - val_loss: 1.0131\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.1088 - val_loss: 1.0165\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0815 - val_loss: 1.0111\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.0515 - val_loss: 1.0127\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 1.0390 - val_loss: 1.0168\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.0128 - val_loss: 1.0065\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.9636 - val_loss: 1.0036\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.9501 - val_loss: 1.0337\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.9087 - val_loss: 1.0022\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.8756 - val_loss: 0.9895\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 0.8350 - val_loss: 1.0049\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 0.8121 - val_loss: 1.2696\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 0.8034 - val_loss: 0.9827\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 0.7150 - val_loss: 1.0171\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 0.6675 - val_loss: 1.0513\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 0.6008 - val_loss: 1.0828\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 0.5674 - val_loss: 1.0070\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 0.4922 - val_loss: 1.2197\n",
      "Epoch 00024: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.4521 - val_loss: 1.2600\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2724 - val_loss: 1.1564\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2084 - val_loss: 1.0347\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1652 - val_loss: 0.9998\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.1378 - val_loss: 0.9884\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.1030 - val_loss: 1.0129\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0769 - val_loss: 0.9837\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0285 - val_loss: 0.9893\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.0117 - val_loss: 0.9913\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 0.9827 - val_loss: 0.9717\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.9417 - val_loss: 0.9654\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.9145 - val_loss: 0.9851\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.8214 - val_loss: 0.9429\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.8227 - val_loss: 0.9352\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.7962 - val_loss: 0.9920\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.7420 - val_loss: 1.0107\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 0.7186 - val_loss: 0.9870\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 0.6008 - val_loss: 1.2059\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 0.4856 - val_loss: 1.1968\n",
      "Epoch 00019: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.3162 - val_loss: 1.4625\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1323 - val_loss: 1.3776\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0867 - val_loss: 1.5707\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0722 - val_loss: 1.5291\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.0314 - val_loss: 1.5766\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9842 - val_loss: 1.4059\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0102 - val_loss: 1.5138\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.5416 - val_loss: 1.9503\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3264 - val_loss: 1.3791\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2012 - val_loss: 1.3882\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0629 - val_loss: 1.7998\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.0685 - val_loss: 1.6151\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.0265 - val_loss: 1.5268\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.9889 - val_loss: 1.6540\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.3222 - val_loss: 1.5505\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1230 - val_loss: 1.3910\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0781 - val_loss: 1.7200\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0674 - val_loss: 1.6760\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.0089 - val_loss: 1.4955\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9801 - val_loss: 1.5478\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.9298 - val_loss: 1.7183\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.4863 - val_loss: 1.7877\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3566 - val_loss: 1.4402\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.1944 - val_loss: 1.3586\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.1002 - val_loss: 1.5882\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.0400 - val_loss: 1.5436\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.0456 - val_loss: 1.5734\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0084 - val_loss: 1.5638\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 0.9820 - val_loss: 1.6559\n",
      "Epoch 00008: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.3349 - val_loss: 1.6384\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1396 - val_loss: 1.3543\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0636 - val_loss: 1.6593\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0013 - val_loss: 1.4776\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.0351 - val_loss: 1.4370\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.0403 - val_loss: 1.3859\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.9880 - val_loss: 1.5215\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.3869 - val_loss: 1.9249\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2453 - val_loss: 1.3884\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.1379 - val_loss: 1.5769\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0336 - val_loss: 1.5384\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.9984 - val_loss: 1.6735\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9651 - val_loss: 1.7681\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.9542 - val_loss: 1.7493\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.4353 - val_loss: 1.7717\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2009 - val_loss: 1.4100\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0925 - val_loss: 1.8006\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0550 - val_loss: 1.5613\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.0145 - val_loss: 1.6125\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9727 - val_loss: 1.5321\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.9388 - val_loss: 1.6461\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.6357 - val_loss: 1.9688\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3101 - val_loss: 1.3935\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2513 - val_loss: 1.3789\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0872 - val_loss: 1.6601\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.9957 - val_loss: 1.7152\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.0004 - val_loss: 1.9592\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.9143 - val_loss: 1.7657\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 0.8976 - val_loss: 1.7877\n",
      "Epoch 00008: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.5163 - val_loss: 2.0771\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2541 - val_loss: 1.4018\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2032 - val_loss: 1.4046\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0633 - val_loss: 1.7368\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 1.0362 - val_loss: 1.7716\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.0242 - val_loss: 1.9920\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0241 - val_loss: 1.6208\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.2384 - val_loss: 1.4209\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1086 - val_loss: 1.4429\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0621 - val_loss: 1.5033\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.9859 - val_loss: 1.6924\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.9635 - val_loss: 1.5781\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9848 - val_loss: 1.5084\n",
      "Epoch 00006: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.3712 - val_loss: 1.0247\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1147 - val_loss: 1.1920\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0677 - val_loss: 0.8739\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.9554 - val_loss: 0.8822\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.9226 - val_loss: 0.9360\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9037 - val_loss: 0.9505\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.8658 - val_loss: 0.9635\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 0.8288 - val_loss: 0.8006\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 0.8210 - val_loss: 0.9850\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 0.7236 - val_loss: 0.8739\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.6838 - val_loss: 1.0551\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.6711 - val_loss: 0.7919\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.7129 - val_loss: 0.8333\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.5816 - val_loss: 0.9378\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.5034 - val_loss: 0.9428\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.4975 - val_loss: 1.5485\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 0.4417 - val_loss: 1.5328\n",
      "Epoch 00017: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.5857 - val_loss: 1.1795\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3812 - val_loss: 1.1123\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.1480 - val_loss: 1.0892\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0122 - val_loss: 0.8056\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.9513 - val_loss: 0.8211\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.8967 - val_loss: 0.7997\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.8744 - val_loss: 0.8408\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 0.8302 - val_loss: 0.7965\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 0.8083 - val_loss: 0.7796\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 0.7941 - val_loss: 0.8104\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.7306 - val_loss: 0.9080\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.7192 - val_loss: 0.8472\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.7048 - val_loss: 0.8110\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.6901 - val_loss: 0.8967\n",
      "Epoch 00014: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.5288 - val_loss: 1.2408\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2990 - val_loss: 1.1050\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.1540 - val_loss: 0.9960\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0506 - val_loss: 0.8341\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.9995 - val_loss: 0.9314\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9580 - val_loss: 0.8622\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.9357 - val_loss: 0.9442\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 0.8760 - val_loss: 0.8086\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 0.8322 - val_loss: 0.8442\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 0.7936 - val_loss: 0.8527\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.7513 - val_loss: 0.8923\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.7151 - val_loss: 0.7809\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.6713 - val_loss: 0.8581\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.6278 - val_loss: 0.9328\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.5676 - val_loss: 0.7908\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.5410 - val_loss: 0.8247\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 0.4770 - val_loss: 0.8665\n",
      "Epoch 00017: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.3110 - val_loss: 1.0200\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.0808 - val_loss: 1.0377\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0128 - val_loss: 0.7658\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.9396 - val_loss: 0.9061\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.9517 - val_loss: 0.8788\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9180 - val_loss: 0.8400\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.8486 - val_loss: 0.7980\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 0.8384 - val_loss: 0.7499\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 0.7829 - val_loss: 0.9008\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 0.7709 - val_loss: 0.7451\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.7446 - val_loss: 0.8586\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.6968 - val_loss: 0.8022\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.6578 - val_loss: 0.7987\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.5889 - val_loss: 0.8030\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.5559 - val_loss: 0.7890\n",
      "Epoch 00015: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.4146 - val_loss: 1.0727\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1530 - val_loss: 1.1102\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0321 - val_loss: 0.8077\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.9581 - val_loss: 0.9564\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.9073 - val_loss: 0.7922\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.9317 - val_loss: 0.8554\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.8835 - val_loss: 0.8128\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 0.8032 - val_loss: 0.7827\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 0.7769 - val_loss: 0.8838\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 0.7186 - val_loss: 0.7590\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.7676 - val_loss: 0.7984\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.6933 - val_loss: 0.9676\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.6683 - val_loss: 1.1782\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.6932 - val_loss: 0.7273\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.5698 - val_loss: 0.8429\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.5011 - val_loss: 0.8745\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 0.4113 - val_loss: 1.0434\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 0.3395 - val_loss: 1.3829\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 0.3257 - val_loss: 0.9633\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "for ensemble_id in range(n_experiment):\n",
    "    X_oracle, y_oracle = get_experimental_X_y_by_EditDist(\n",
    "        X, y_gt, WT_AAV_encoding, train_size=train_size, \n",
    "        max_edit_distance=1, random_state=ensemble_id, \n",
    "        return_y_noise=True)\n",
    "    train_and_save_oracles(\n",
    "        X_oracle, y_oracle, suffix='Single', protein='AAV',\n",
    "        train_size=train_size, n_models=5, \n",
    "        ensemble_id=ensemble_id, n_char=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain oracle trained with bottom 20% fit sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.6446 - val_loss: 1.1653\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2737 - val_loss: 0.9435\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.9320 - val_loss: 0.9189\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.7412 - val_loss: 0.5398\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.3674 - val_loss: 0.3176\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.0029 - val_loss: 0.4384\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -2.3278e-01 - val_loss: 0.7330\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -3.3733e-01 - val_loss: 1.1727\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -3.8766e-01 - val_loss: 1.9084\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -4.8807e-01 - val_loss: 1.8214\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.5384 - val_loss: 1.0596\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1909 - val_loss: 0.8950\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.8149 - val_loss: 0.7153\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.4089 - val_loss: 0.2387\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: -3.0268e-02 - val_loss: 0.3956\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -2.3978e-01 - val_loss: 0.7401\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -2.4598e-01 - val_loss: 0.6015\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -2.6880e-01 - val_loss: 0.3937\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -5.2396e-01 - val_loss: 0.5974\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.5803 - val_loss: 1.1633\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1700 - val_loss: 0.8637\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.9005 - val_loss: 0.8366\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.6381 - val_loss: 0.4525\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.2645 - val_loss: 0.2551\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -7.8471e-02 - val_loss: 0.2164\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -3.0903e-01 - val_loss: 0.3554\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -4.4698e-01 - val_loss: 0.9487\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -3.7697e-01 - val_loss: 0.6032\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -4.3622e-01 - val_loss: 0.6256\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: -5.5476e-01 - val_loss: 1.0667\n",
      "Epoch 00011: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.6956 - val_loss: 1.1379\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2660 - val_loss: 1.0628\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.9409 - val_loss: 0.8612\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.6681 - val_loss: 0.4463\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.2276 - val_loss: 0.6132\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -6.7868e-02 - val_loss: 0.9709\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -1.6846e-01 - val_loss: 1.0209\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -3.2004e-01 - val_loss: 0.7306\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -4.3964e-01 - val_loss: 0.9088\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.5726 - val_loss: 1.2642\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2918 - val_loss: 1.0052\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.9618 - val_loss: 0.9577\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.6690 - val_loss: 0.5376\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.2083 - val_loss: 0.7371\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -1.5843e-01 - val_loss: 1.3848\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -2.4243e-01 - val_loss: 2.4024\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -2.0992e-01 - val_loss: 1.6406\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -2.5414e-01 - val_loss: 1.3427\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.9943 - val_loss: 1.0591\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2479 - val_loss: 1.2183\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.1154 - val_loss: 0.9188\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.8428 - val_loss: 0.6587\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.3920 - val_loss: 0.3049\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -5.8246e-02 - val_loss: 0.7792\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -1.9455e-01 - val_loss: 0.9827\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -3.6129e-01 - val_loss: 1.0520\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -4.9469e-01 - val_loss: 1.5158\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -5.6938e-01 - val_loss: 2.4447\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.4306 - val_loss: 1.0702\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.0688 - val_loss: 0.7698\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.7214 - val_loss: 0.5294\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.2583 - val_loss: 0.1979\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: -2.2632e-01 - val_loss: 0.6228\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -4.1428e-01 - val_loss: 1.5365\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -5.6377e-01 - val_loss: 1.4276\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -5.4469e-01 - val_loss: 1.8524\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -7.2942e-01 - val_loss: 2.0807\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.3438 - val_loss: 1.2921\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.0839 - val_loss: 0.7603\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.6536 - val_loss: 0.5562\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.2302 - val_loss: 0.3968\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: -1.5394e-01 - val_loss: 0.7115\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -2.7414e-01 - val_loss: 1.3301\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -2.7685e-01 - val_loss: 1.7442\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -3.8126e-01 - val_loss: 1.4567\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -4.5982e-01 - val_loss: 1.6919\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.8316 - val_loss: 1.2088\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3557 - val_loss: 1.1172\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0275 - val_loss: 1.0619\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.8517 - val_loss: 0.6912\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.4000 - val_loss: 0.5403\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -1.2582e-01 - val_loss: 1.3702\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -3.9868e-01 - val_loss: 2.8438\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -1.7689e-01 - val_loss: 2.6244\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -3.0529e-01 - val_loss: 1.6396\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -4.1621e-01 - val_loss: 1.7724\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.8723 - val_loss: 1.2296\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2585 - val_loss: 0.9480\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.9918 - val_loss: 0.9344\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.8460 - val_loss: 0.6581\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.5453 - val_loss: 0.3433\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.1828 - val_loss: 0.4472\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -1.1897e-01 - val_loss: 0.4592\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -1.7832e-01 - val_loss: 0.6178\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -4.3712e-01 - val_loss: 0.7685\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -4.3432e-01 - val_loss: 0.7051\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 2.1630 - val_loss: 1.1313\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3115 - val_loss: 1.3486\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.1845 - val_loss: 1.0653\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.9603 - val_loss: 0.8661\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.5994 - val_loss: 0.5565\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.1108 - val_loss: 0.7802\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -2.5997e-01 - val_loss: 3.0574\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -9.9665e-02 - val_loss: 2.3764\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -1.2784e-01 - val_loss: 1.8629\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -2.1196e-01 - val_loss: 1.4363\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.5827 - val_loss: 1.1574\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2598 - val_loss: 0.9813\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.8786 - val_loss: 0.7556\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.5876 - val_loss: 0.3846\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.0674 - val_loss: 0.1541\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -2.6395e-01 - val_loss: 0.3961\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -2.5443e-01 - val_loss: 1.6335\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -1.8104e-01 - val_loss: 0.8352\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -3.0576e-01 - val_loss: 0.3381\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -3.5239e-01 - val_loss: 0.2411\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.9880 - val_loss: 1.0594\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2074 - val_loss: 1.2283\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0600 - val_loss: 0.9248\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.7870 - val_loss: 0.5975\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.2938 - val_loss: 0.4166\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -1.4490e-01 - val_loss: 1.3109\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -2.1685e-01 - val_loss: 1.4636\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -1.8462e-01 - val_loss: 0.9679\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -4.4028e-01 - val_loss: 1.2163\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -5.6193e-01 - val_loss: 1.8001\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.3816 - val_loss: 1.3400\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.0942 - val_loss: 0.8549\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.7771 - val_loss: 0.6381\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.2992 - val_loss: 0.6930\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: -9.9768e-02 - val_loss: 1.8151\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -1.7568e-01 - val_loss: 2.9225\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -4.3783e-01 - val_loss: 2.8606\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -4.6789e-01 - val_loss: 3.3641\n",
      "Epoch 00008: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.2977 - val_loss: 1.1594\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 0.9762 - val_loss: 0.7452\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.5414 - val_loss: 0.5815\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.1272 - val_loss: 0.8394\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: -2.1230e-01 - val_loss: 1.6168\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -4.1324e-01 - val_loss: 2.1242\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -3.8556e-01 - val_loss: 1.8423\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -3.8592e-01 - val_loss: 1.9896\n",
      "Epoch 00008: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.6535 - val_loss: 1.0346\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.0774 - val_loss: 0.8401\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.8470 - val_loss: 0.7101\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.4399 - val_loss: 0.3068\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.0215 - val_loss: 0.4705\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -2.1284e-01 - val_loss: 1.1569\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -3.0357e-01 - val_loss: 1.1711\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -4.1829e-01 - val_loss: 1.2057\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -6.2843e-01 - val_loss: 1.7203\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 2.3470 - val_loss: 0.9337\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1728 - val_loss: 1.1445\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.1190 - val_loss: 0.9760\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.9487 - val_loss: 0.8339\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.6468 - val_loss: 0.3819\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.2236 - val_loss: 0.2334\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -2.3771e-01 - val_loss: 0.8675\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -3.6791e-01 - val_loss: 1.3113\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -1.6284e-01 - val_loss: 0.9721\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -4.5280e-01 - val_loss: 0.8454\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: -5.7005e-01 - val_loss: 1.5236\n",
      "Epoch 00011: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.7818 - val_loss: 1.0582\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2400 - val_loss: 1.0355\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.9428 - val_loss: 0.8750\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.6112 - val_loss: 0.3906\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.0623 - val_loss: 0.6752\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -3.1306e-01 - val_loss: 1.8364\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -3.3130e-01 - val_loss: 2.8145\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -2.6121e-01 - val_loss: 2.2340\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -3.6323e-01 - val_loss: 1.6453\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.4134 - val_loss: 1.1779\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.0841 - val_loss: 0.8351\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.7489 - val_loss: 0.6410\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.3353 - val_loss: 0.6326\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: -8.6067e-02 - val_loss: 1.2511\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -4.2654e-01 - val_loss: 3.3607\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -4.5293e-01 - val_loss: 3.5753\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -5.2196e-01 - val_loss: 4.0282\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -5.2663e-01 - val_loss: 3.9610\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.5166 - val_loss: 1.1901\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1591 - val_loss: 0.8701\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.7881 - val_loss: 0.5496\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.3097 - val_loss: 0.1435\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: -1.6853e-01 - val_loss: 0.6913\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -3.1789e-01 - val_loss: 1.3834\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.0110 - val_loss: 0.5623\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -2.3379e-01 - val_loss: 0.5056\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -3.6887e-01 - val_loss: 0.3650\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.3341 - val_loss: 1.1148\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.0608 - val_loss: 0.7327\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.6160 - val_loss: 0.4189\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.2165 - val_loss: 0.7702\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: -1.3696e-01 - val_loss: 1.0390\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -3.2607e-01 - val_loss: 1.9614\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -4.2929e-01 - val_loss: 1.8606\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -5.6501e-01 - val_loss: 2.5454\n",
      "Epoch 00008: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.5056 - val_loss: 1.2018\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2478 - val_loss: 0.8998\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.8894 - val_loss: 0.8577\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.6271 - val_loss: 0.4575\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.2025 - val_loss: 0.4017\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -2.3593e-01 - val_loss: 0.4246\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -4.6135e-01 - val_loss: 2.1360\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -4.1243e-01 - val_loss: 1.2375\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -8.1689e-02 - val_loss: 0.6917\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -2.0741e-01 - val_loss: 0.4393\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.5724 - val_loss: 1.1086\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2216 - val_loss: 0.9607\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.8466 - val_loss: 0.9237\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.4769 - val_loss: 0.5781\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.0170 - val_loss: 1.3145\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -3.4595e-01 - val_loss: 3.9992\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -4.4514e-01 - val_loss: 8.8679\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -9.6133e-02 - val_loss: 3.7775\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -2.6312e-01 - val_loss: 2.0911\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.3960 - val_loss: 1.1716\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 0.9264 - val_loss: 0.8415\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.7211 - val_loss: 0.6039\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.3055 - val_loss: 0.4752\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: -1.1486e-01 - val_loss: 0.9118\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -3.5332e-01 - val_loss: 1.8545\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -4.1205e-01 - val_loss: 2.6200\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -3.5482e-01 - val_loss: 1.9459\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -5.9632e-01 - val_loss: 1.8838\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.8249 - val_loss: 1.1115\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3025 - val_loss: 1.0055\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.9542 - val_loss: 1.0261\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.8071 - val_loss: 0.6543\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.4133 - val_loss: 0.4444\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -6.3130e-03 - val_loss: 0.4967\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -2.8101e-01 - val_loss: 1.1168\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -3.9723e-01 - val_loss: 0.9111\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -3.7449e-01 - val_loss: 1.2017\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -4.1660e-01 - val_loss: 0.9808\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.7613 - val_loss: 1.1407\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3461 - val_loss: 1.1160\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0368 - val_loss: 0.9629\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.8134 - val_loss: 0.6163\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.3431 - val_loss: 0.4091\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -1.4446e-01 - val_loss: 1.3821\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -2.9562e-01 - val_loss: 2.1445\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -2.4099e-01 - val_loss: 2.0017\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -3.9210e-01 - val_loss: 1.3570\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -4.2889e-01 - val_loss: 1.4410\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.9343 - val_loss: 1.0214\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2231 - val_loss: 0.9697\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.9396 - val_loss: 0.9948\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.7416 - val_loss: 0.6119\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.3307 - val_loss: 0.6045\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -7.6164e-02 - val_loss: 1.1593\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -2.3751e-01 - val_loss: 1.4786\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -3.2561e-01 - val_loss: 1.2084\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -5.1488e-01 - val_loss: 1.3909\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -4.6505e-01 - val_loss: 1.8696\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 2.0308 - val_loss: 1.0012\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1814 - val_loss: 1.0524\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.9918 - val_loss: 0.9043\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.7549 - val_loss: 0.5689\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.2916 - val_loss: 0.3407\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -1.0808e-01 - val_loss: 0.6983\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -3.8950e-01 - val_loss: 2.1003\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -4.7490e-01 - val_loss: 1.4332\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -3.5574e-01 - val_loss: 1.2964\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -6.0122e-01 - val_loss: 1.4151\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.4205 - val_loss: 1.1740\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1062 - val_loss: 0.8923\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.8097 - val_loss: 0.8206\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.4939 - val_loss: 0.4544\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.0236 - val_loss: 0.8322\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -2.7584e-01 - val_loss: 2.5333\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -2.5871e-01 - val_loss: 1.8016\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -2.6930e-01 - val_loss: 1.5902\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -3.7891e-01 - val_loss: 1.7925\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.5398 - val_loss: 1.1075\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2262 - val_loss: 0.9166\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.8482 - val_loss: 0.8545\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.4884 - val_loss: 0.3549\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: -1.6126e-02 - val_loss: 0.5776\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -3.1869e-01 - val_loss: 2.4603\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -5.1531e-02 - val_loss: 1.3605\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -2.3439e-01 - val_loss: 0.9674\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -4.7124e-01 - val_loss: 0.8805\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.4328 - val_loss: 1.1347\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1381 - val_loss: 0.8747\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.8123 - val_loss: 0.7822\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.3708 - val_loss: 0.4799\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: -7.1263e-03 - val_loss: 0.7496\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -1.8404e-01 - val_loss: 1.4407\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -4.0953e-01 - val_loss: 1.3464\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -3.6176e-01 - val_loss: 1.4878\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -5.7439e-01 - val_loss: 2.4739\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.3135 - val_loss: 1.1511\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.0074 - val_loss: 0.7788\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.6074 - val_loss: 0.3946\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.2316 - val_loss: 0.3527\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: -2.0502e-01 - val_loss: 1.1152\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -4.0008e-01 - val_loss: 0.9255\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -7.5490e-02 - val_loss: 0.8372\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -1.3000e-01 - val_loss: 0.9973\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -3.1568e-01 - val_loss: 1.0952\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.8600 - val_loss: 1.0053\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2321 - val_loss: 1.0190\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.9923 - val_loss: 0.8819\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.7804 - val_loss: 0.4909\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.3762 - val_loss: 0.2033\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.0184 - val_loss: 0.0342\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -1.2665e-01 - val_loss: 0.2008\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -3.6437e-01 - val_loss: 0.8302\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -4.2611e-01 - val_loss: 0.4185\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -4.5368e-01 - val_loss: 0.3810\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: -4.7287e-01 - val_loss: 0.2275\n",
      "Epoch 00011: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.2927 - val_loss: 1.1162\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 0.9823 - val_loss: 0.7944\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.6426 - val_loss: 0.4167\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.2170 - val_loss: 0.4322\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: -2.0380e-01 - val_loss: 0.9510\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -4.2883e-01 - val_loss: 1.6711\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -4.9823e-01 - val_loss: 2.6402\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -6.0482e-01 - val_loss: 2.0669\n",
      "Epoch 00008: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.6190 - val_loss: 1.0916\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2057 - val_loss: 0.9346\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.9069 - val_loss: 0.7821\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.6033 - val_loss: 0.3491\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.1648 - val_loss: -2.1485e-02\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -1.7612e-01 - val_loss: 0.0673\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -2.5016e-01 - val_loss: 0.3308\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -2.2014e-01 - val_loss: 0.2056\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -2.9296e-01 - val_loss: 0.0748\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -3.0852e-01 - val_loss: 0.1927\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 2.1265 - val_loss: 1.0126\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2291 - val_loss: 1.0175\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.9867 - val_loss: 1.0775\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.8898 - val_loss: 0.8260\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.6014 - val_loss: 0.6788\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.2224 - val_loss: 0.8845\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -1.7234e-01 - val_loss: 2.3490\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -3.1220e-01 - val_loss: 5.2647\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -2.0539e-01 - val_loss: 3.9902\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -7.7704e-02 - val_loss: 3.1604\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 2.3371 - val_loss: 0.9533\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2325 - val_loss: 1.1951\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0961 - val_loss: 0.9986\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.9614 - val_loss: 0.8738\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.6770 - val_loss: 0.6501\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.3325 - val_loss: 0.6102\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -6.6987e-02 - val_loss: 1.3604\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -3.9337e-01 - val_loss: 4.2477\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -4.2069e-01 - val_loss: 5.3348\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -2.6841e-01 - val_loss: 4.5020\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: -3.2301e-01 - val_loss: 3.2449\n",
      "Epoch 00011: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.4619 - val_loss: 1.1032\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1748 - val_loss: 0.9000\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.7320 - val_loss: 0.8333\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.3090 - val_loss: 0.7903\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: -2.8005e-02 - val_loss: 1.9990\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -2.6010e-01 - val_loss: 2.9789\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -4.6198e-01 - val_loss: 4.4234\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -5.1508e-01 - val_loss: 5.6227\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -3.7734e-01 - val_loss: 5.6093\n",
      "Epoch 00009: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.9557 - val_loss: 1.0884\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.4005 - val_loss: 1.1556\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.1353 - val_loss: 1.1127\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.9851 - val_loss: 0.8877\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.5678 - val_loss: 0.5140\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.0931 - val_loss: 1.0449\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -1.7368e-01 - val_loss: 2.0201\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -2.4305e-01 - val_loss: 2.1883\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -3.7757e-01 - val_loss: 2.9221\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -4.4977e-01 - val_loss: 3.0188\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.8510 - val_loss: 1.1159\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2885 - val_loss: 1.0913\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.0047 - val_loss: 0.9560\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.8236 - val_loss: 0.6772\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.4027 - val_loss: 0.5262\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -3.6592e-02 - val_loss: 0.9841\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -1.7549e-01 - val_loss: 1.8768\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -3.1963e-01 - val_loss: 2.2475\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -4.0477e-01 - val_loss: 2.2561\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -5.7615e-01 - val_loss: 2.7096\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.7741 - val_loss: 1.0490\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2213 - val_loss: 1.0768\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.9624 - val_loss: 0.8470\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.7200 - val_loss: 0.4977\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.2260 - val_loss: 0.3187\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -7.0775e-02 - val_loss: 0.6365\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -7.2591e-02 - val_loss: 0.5447\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -8.1096e-02 - val_loss: 0.5978\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -3.2640e-01 - val_loss: 0.8183\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -4.2676e-01 - val_loss: 1.1922\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 2.4090 - val_loss: 1.0137\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2648 - val_loss: 1.2752\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.2108 - val_loss: 1.0653\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0452 - val_loss: 0.9391\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.8118 - val_loss: 0.6138\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.3909 - val_loss: 0.3339\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -5.6151e-02 - val_loss: 0.5234\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -3.5540e-01 - val_loss: 1.3997\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -3.7593e-01 - val_loss: 1.5396\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -1.7535e-01 - val_loss: 1.3876\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: -3.5731e-01 - val_loss: 1.2053\n",
      "Epoch 00011: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.1696 - val_loss: 0.8742\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 0.6811 - val_loss: 0.6076\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.1978 - val_loss: 1.2550\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.2480 - val_loss: 1.1287\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.0478 - val_loss: 0.6907\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -1.4969e-01 - val_loss: 0.8324\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -3.2593e-01 - val_loss: 1.6020\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.3217 - val_loss: 1.1670\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 0.9675 - val_loss: 1.0448\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.7533 - val_loss: 0.6856\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.3705 - val_loss: 0.6958\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.0035 - val_loss: 1.3901\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -1.4538e-01 - val_loss: 1.7789\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -9.5572e-02 - val_loss: 1.4172\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -1.0453e-01 - val_loss: 1.4116\n",
      "Epoch 00008: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.9332 - val_loss: 1.2127\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3666 - val_loss: 1.2869\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.1438 - val_loss: 0.9889\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.9402 - val_loss: 0.7714\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.5797 - val_loss: 0.4676\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.1486 - val_loss: 0.2139\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -2.3525e-01 - val_loss: 1.5230\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -1.0258e-01 - val_loss: 0.9546\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -2.1339e-01 - val_loss: 0.8042\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -3.2995e-01 - val_loss: 0.7562\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: -4.5036e-01 - val_loss: 1.2097\n",
      "Epoch 00011: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.4756 - val_loss: 1.1753\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.0852 - val_loss: 0.9260\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.8913 - val_loss: 0.8721\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.5869 - val_loss: 0.4970\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.2425 - val_loss: 0.3833\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -9.5840e-02 - val_loss: 0.5216\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -3.2941e-01 - val_loss: 1.0505\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -4.0203e-01 - val_loss: 1.1593\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -2.7480e-01 - val_loss: 0.9472\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -4.1795e-01 - val_loss: 0.9356\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.0599 - val_loss: 0.7499\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 0.5945 - val_loss: 0.3653\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.0974 - val_loss: 0.5415\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: -2.3804e-01 - val_loss: 0.8496\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: -3.7763e-01 - val_loss: 1.2538\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -4.7938e-01 - val_loss: 1.3468\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -5.4787e-01 - val_loss: 1.5713\n",
      "Epoch 00007: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 2.9369 - val_loss: 0.9095\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3064 - val_loss: 1.2702\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 1.1978 - val_loss: 1.0642\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 1.0927 - val_loss: 1.0679\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.9695 - val_loss: 0.8086\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.7184 - val_loss: 0.5662\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.4094 - val_loss: 0.3905\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 0.0459 - val_loss: 0.2156\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -2.7177e-01 - val_loss: 0.5291\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -9.1536e-02 - val_loss: 1.0170\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.0963 - val_loss: 0.5426\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: -1.3535e-01 - val_loss: 0.6324\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: -1.1341e-02 - val_loss: 0.8408\n",
      "Epoch 00013: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.4173 - val_loss: 1.2159\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.1082 - val_loss: 0.7938\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.7174 - val_loss: 0.3378\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.1654 - val_loss: 0.1283\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: -1.7227e-01 - val_loss: -5.2355e-02\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -3.1634e-01 - val_loss: 0.0557\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -4.5831e-01 - val_loss: 0.3597\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -4.4891e-01 - val_loss: 0.2566\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -4.9974e-01 - val_loss: 0.3224\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -5.4462e-01 - val_loss: 0.5487\n",
      "Epoch 00010: early stopping\n",
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 1.6571 - val_loss: 1.1757\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.2553 - val_loss: 0.9864\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.9002 - val_loss: 0.8313\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.5170 - val_loss: 0.2749\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.0062 - val_loss: -4.5995e-02\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: -3.1915e-01 - val_loss: 0.2187\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: -3.9124e-01 - val_loss: 0.4866\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: -5.0733e-01 - val_loss: 0.8125\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: -5.1490e-01 - val_loss: 0.6874\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: -6.7853e-01 - val_loss: 0.6994\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "for ensemble_id in range(n_experiment):\n",
    "    X_oracle, y_oracle = get_experimental_X_y(\n",
    "        X, y_gt, percentile=20, train_size=train_size, \n",
    "        random_state=ensemble_id, return_y_noise=True)\n",
    "    train_and_save_oracles(\n",
    "        X_oracle, y_oracle, \n",
    "        protein = \"AAV\", suffix='AAV', train_size=train_size, \n",
    "        n_models=5, ensemble_id=ensemble_id, n_char=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracles = load_oracles(protein='AAV', suffix='AAV', \n",
    "                       n_models=5, ensemble_id=2, train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_balaji_predictions(oracles, X[60:120])\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "386218770bb7053658aedbdb94aaaba888065d92b04918111f39a883f4943438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
